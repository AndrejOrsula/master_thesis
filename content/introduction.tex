\chapter{Introduction}

Grasping is a fundamental manipulation skill that is essential for a variety of everyday tasks that interact with the environment. Stacking, inserting, pouring, cutting and writing are all examples of skills that require an object or a tool to be firmly grasped prior to performing them. A hierarchy of such subroutines can be assembled in order to accomplish more complex goals, which in turn requires grasping of diverse objects that can differ in their appearance, geometry as well as inertial and mechanical properties. Despite the uniqueness this might bring to each individual grasp, a versatile robot should generalize over different objects and scenarios instead of treating them as distinct subtasks.

Task-specific algorithms are often analytically developed for a specific gripper on a set of objects via time-consuming approach. Despite effectiveness of such methods, they usually lead to a solution that lacks the required generalization and even slight differences in the process or manipulated objects might require manual reprogramming \cite{sahbani_overview_2012}.
Empirical approaches were introduced to overcome the difficulties with analytical grasping by progressively learning through sampling and training. In this way, supervised learning provides a way to learn grasp synthesis from a dataset that is labelled with analytical grasp metrics, however, this approach requires large volume of data in order to achieve the desired generalization \cite{mahler_dex-net_2017}. Although imitation learning allows robots to quickly learn simple grasps from demonstration, large amount of human expert demonstrations is similarly required, which can become too costly and time-consuming before a general policy is learned. Reinforcement Learning (RL) could offer a solution to this problem \cite{sutton_reinforcement_2018}, as self-supervision provides the means for a robot to progressively become better at grasping via repeated experience and minimal human involvement. The popularity of RL has significantly increased in recent years, especially due to the noteworthy results obtained by Deep Reinforcement Learning (DRL). Several publications demonstrated that DRL can be used to achieve human level performance in tasks such as playing Atari games \cite{mnih_human-level_2015}, or even beating world champion in the boardgame Go \cite{silver_mastering_2017} or real-time strategy game StarCraft II \cite{vinyals_grandmaster_2019}. Moreover, \citet{schrittwieser_mastering_2020} established just how far DRL has come with a single algorithm that can achieve superhuman performance in multiple domains, i.e. Go, chess, shogi and 57 Atari games, by learning a model without any knowledge of the game rules.

