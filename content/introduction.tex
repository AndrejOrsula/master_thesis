\chapter{Introduction}

% Intro to grasping
Grasping is a fundamental manipulation skill that is essential for a variety of everyday tasks. Stacking, inserting, pouring, cutting and writing are all examples of such tasks that require an object or a tool to be firmly grasped prior to performing them. A hierarchy of subroutines can be assembled together in order to accomplish more complex goals, which in turn requires grasping of diverse objects that can differ in their appearance, geometry as well as inertial and mechanical properties. Despite the uniqueness this might bring to each individual grasp, a versatile robot should generalize over different objects and scenarios instead of treating them as distinct subtasks.

% Brief related works; analytical approaches, supervised learning, imitation learning, reinforcement learning (elaborated more with popular examples)
Task-specific algorithms are often analytically developed for a specific gripper on a set of objects via time-consuming approach. Despite effectiveness of such methods, they usually lead to a solution that lacks the required generalization and even slight differences in the process or manipulated objects might require manual reprogramming \cite{sahbani_overview_2012}. Empirical approaches were introduced to overcome the difficulties with analytical grasping by progressively learning through sampling and training. In this way, supervised learning provides a way to learn grasp synthesis from a dataset that is labelled with analytical grasp metrics, however, this approach requires a large volume of data in order to achieve the desired generalization \cite{mahler_dex-net_2017}. Although imitation learning allows robots to quickly learn simple grasps \cite{zhang_deep_2018}, the amount of required human expert demonstrations can also become too costly and time-consuming before a general policy is learned. Reinforcement learning (RL) \cite{sutton_reinforcement_2018} could offer a solution to this problem, as self-supervision provides the means for a robot to progressively become better at grasping via repeated experience and minimal human involvement. The popularity of RL has significantly increased in recent years, especially due to the noteworthy results obtained by deep reinforcement learning (DRL). Several publications demonstrated that DRL can be used to achieve human level performance in tasks such as playing Atari games \cite{mnih_human-level_2015}, or even beating world champions in the boardgame Go \cite{silver_mastering_2017} and real-time strategy game StarCraft II \cite{vinyals_grandmaster_2019}. Moreover, \citet{schrittwieser_mastering_2020} established just how far DRL has come with a single algorithm that can achieve superhuman performance by learning a model without any prior knowledge of the game rules in multiple domains, i.e.~Go, Chess, Shogi and 57 Atari games.

% Mention real-world RL applications, focus on grasping, list challenges with RL
While games with a well-defined set of rules are popular benchmarks for developing and testing algorithms, RL has also been employed for several real-world applications such as finance \cite{fischer_reinforcement_2018}, industrial process control \cite{nian_review_2020}, scheduling \cite{shyalika_reinforcement_2020} and robotic manipulation \cite{kroemer_review_2021}. Among these, RL has likewise gained popularity in robotic grasping due to its flexibility. However, there are many challenges in applying RL to solve robotics problems with high-dimensional continuous action and observation spaces \cite{kroemer_review_2021}. It can be difficult to design a suitable reward function because robotics tasks such as grasping require multiple objectives to be optimised simultaneously, e.g.~grasp an object with as little energy while avoiding all obstacles. Furthermore, collection of training data on physical robots is a time-consuming and potentially unsafe process, therefore, robotics simulators are commonly utilised because they provide a less expensive and much faster way to train RL agents. Unfortunately, this often introduces a reality gap between the virtual and real-world domain that needs to be addressed via sim-to-real approaches.

% End-to-end approaches, lead into 3D observations
End-to-end DRL approaches for solving robotic grasping have become more attractive in recent years due to their ability to directly map raw observations into actions, where visual observations in form of 2D RGB and 2.5D RGB-D images are the most common. Features from these images are typically extracted by utilising 2D convolutions, which unfortunately do not provide the required level of generalisation over the depth and spatial orientation \cite{gualtieri_pick_2018}. Since the underlying representation of the scene in which robot operates is 3D, representing observations with 3D data structures might provide benefits in terms of generalisation. Therefore, this work aims to investigate the advantages of utilising 3D representation for observations in the context of robotic grasping.

% Contributions of this work
The primary focus of this work is to apply DRL to robotic grasping of diverse objects with the use of compact 3D observations in form of octrees. The key contributions are listed below.

\begin{itemize}
    \item \textbf{Simulated Environment for Grasping with Domain Randomization} -- A novel simulated environment for robotic grasping in the context of RL research is developed in this work. It utilises realistic 3D scanned objects and extensive domain randomization in order to enable sim-to-real transfer. The environment is developed on top of Ignition Gazebo\footnote{\href{https://ignitionrobotics.org}{https://ignitionrobotics.org}} robotics simulator that is interfaced by the use of Gym-Ignition \cite{ferigo_gym-ignition_2020} to provide compatibility with other OpenAI Gym environments \cite{brockman_openai_2016}.
    \item \textbf{Octree Observations for End-to-End Grasping with DRL} -- This work introduces a novel approach for utilising octree-based visual observations for end-to-end robotic grasping with DRL. Octrees provide an efficient 3D data representation with a regular structure that enables the use of 3D convolutions to extract spatial features. Furthermore, the use of 3D representation promotes invariance to camera pose, which further improves sim-to-real transfer to various real-world setups.
    \item \textbf{Curriculum Learning} -- A curriculum was developed for the grasping task in order to progressively increase its difficulty. Besides common techniques of increasing the workspace size and number of objects, this work investigates the effect of decomposing the full task into sequential sub-tasks with distinct termination states.
    \item \textbf{Comparison of Three Actor-Critic RL Algorithms} -- Three off-policy actor-critic RL algorithms are compared on the developed grasping environment with the proposed octree observations. The compared algorithms are TD3, SAC and TQC.
\end{itemize}

% TODO: Remove curriculum task decomposition
% TODO: Add invariance to robot

% Organisation of this thesis
This thesis has the following organisation. First, various approaches for solving robotic grasping are presented and compared in \autoref{ch:related_work}, alongside 3D data representations and their applicability with deep learning. \hyperref[ch:background]{Chapter~\ref*{ch:background}} presents relevant theory and notation that aids with understanding of this thesis. It is followed by \autoref{ch:problem_formulation} that formulates the full problem that this work addresses. \hyperref[ch:implementation]{Chapter~\ref*{ch:implementation}} then presents the concrete implementation steps that enable subsequent experimental evaluation that is reported in \autoref{ch:experimental_evaluation}. Finally, \hyperref[ch:discussion]{chapters~\ref*{ch:discussion}} and \ref{ch:conclusion} discuss the results and conclude the work presented in this thesis.
