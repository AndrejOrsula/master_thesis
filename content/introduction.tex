\chapter{Introduction}

% Grasping is one of the most fundamental tasks in robotics, however, the complexity of solving this problem increases significantly with the diversity of objects due to the differences in their geometry, mass distribution, compliance and friction. It is of utmost importance to provide a general solution that can reliably manipulate previously unseen objects, yet, task-specific algorithms are often analytically developed for a specific gripper on a set of objects via a time-consuming approach. Reinforcement Learning (RL) could offer a solution to this problem, as self-supervision provides the means for a robot to become progressively better at grasping via repeated experience with minimal human involvement.

% The primary goal of this project is to apply Deep Reinforcement Learning (DRL) to provide a robot with general solution to grasping of novel objects in an unstructured environment that is perceived by one or more RGB-D cameras, while utilising a mechanical gripper. The training of the agent shall be performed in a virtual environment, with the aim to transfer its experience to a real-life physical twin for evaluation of the system.


% \section{Project Focus and Novelty}

% This project shall focus on the implementation of a DRL agent for robotic grasping. However, there are many sub-problems that need to be addressed.

% First of all, literature shall be analysed for learning methods that have previously been applied to manipulation. Simulations are important aspect of DRL training because of the extensive data requirements that these algorithms have, therefore, this project must setup a virtual environment that represents the real world as close as possible. Next aspect is the selection of appropriate DRL algorithm that would be suitable for the problem, i.e. large continuous action space with state that is only partially observable. Since the final goal is to execute the algorithm on a real robot, Sim2Real approaches must be investigated and applied.

% There are several aspects the to input data and actions that will be provided to the DRL agent. Shall the input be pre-processed to provide high-level features, or are raw pixels more general? Shall the agent learn to control the entire kinematic chain, or simply to provide a grasp pose that could be reached with the use of other algorithms? Too many questions...

% Possible directions and novelties that this project could explore are described below.

% \subsection{Possible Novelty \#1 - DRL on Point Clouds}

% End-to-end approaches, in which raw 2D image inputs are mapped directly into actions, are common. Different image formats have been applied; RGB, greyscale, depth or their combination, e.g. RGD. These methods exploit the spatial relations of 2-D RGB or 2.5-D RGB-D images by applying convolutional layers in the non-linear function approximator, (deep) neural networks. However, the underlying representation of the scene is 3D, therefore, operating on structures that represent the volumetric space might be advantageous. There are several ways in which this space could be represented, e.g. cubic/spherical/cylindrical voxelgrid, octomap, something with normal maps, others?

% Note: So far, I have not found any papers looking into this.

